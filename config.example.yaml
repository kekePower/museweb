# MuseWeb Configuration

server:
  address: "127.0.0.1"
  port: "8000"
  prompts_dir: "./prompts"
  # Enable debug mode to see detailed HTTP request/response logs (true/false)
  debug: false

model:
  # The AI backend to use ('ollama' or 'openai')
  backend: "openai"
  # The model name to use for the selected backend
  name: "gpt-4.1-nano"
  # Disable the thinking tag for DeepSeek and r1-1776 models (true/false)
  disable_thinking: false

openai:
  # Your OpenAI API key. Can be left blank if using the OPENAI_API_KEY environment variable.
  api_key: ""
  # The base URL for the OpenAI API. Useful for local models like LM Studio.
  api_base: "http://api.openai.com/v1"

ollama:
  # Your Ollama API key. Can be left blank if using the OLLAMA_API_KEY environment variable.
  api_key: ""
  # Base URL for your local Ollama server.
  api_base: "http://localhost:11434"
